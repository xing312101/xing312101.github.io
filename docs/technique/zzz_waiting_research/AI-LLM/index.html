<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-technique/zzz_waiting_research/AI-LLM" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.5.2">
<title data-rh="true">AI | Xing312101&#x27;s Life Notes</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://xing312101.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://xing312101.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://xing312101.github.io/docs/technique/zzz_waiting_research/AI-LLM"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="AI | Xing312101&#x27;s Life Notes"><meta data-rh="true" name="description" content="tokenization"><meta data-rh="true" property="og:description" content="tokenization"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://xing312101.github.io/docs/technique/zzz_waiting_research/AI-LLM"><link data-rh="true" rel="alternate" href="https://xing312101.github.io/docs/technique/zzz_waiting_research/AI-LLM" hreflang="en"><link data-rh="true" rel="alternate" href="https://xing312101.github.io/docs/technique/zzz_waiting_research/AI-LLM" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/rss.xml" title="Xing312101&#39;s Life Notes RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Xing312101&#39;s Life Notes Atom Feed"><link rel="stylesheet" href="/assets/css/styles.4325e046.css">
<script src="/assets/js/runtime~main.57192997.js" defer="defer"></script>
<script src="/assets/js/main.61ac2569.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/xing_icon.svg" alt="Xing312101&#x27;s life" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/xing_icon.svg" alt="Xing312101&#x27;s life" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Xing312101&#x27;s life notes</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/technique/">Technique</a><a class="navbar__item navbar__link" href="/docs/english/">English</a><a class="navbar__item navbar__link" href="/docs/japanese/">Japanese</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/xing312101" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link"></a><a href="https://www.instagram.com/xing312101/?utm_source=qr" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-ig-link"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/">Notes</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/angular/">Angular</a><button aria-label="Expand sidebar category &#x27;Angular&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/angularjs/">AngularJS</a><button aria-label="Expand sidebar category &#x27;AngularJS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/aws/">AWS</a><button aria-label="Expand sidebar category &#x27;AWS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/bootstrap/">Bootstrap</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/cordova/">Cordova Webview</a><button aria-label="Expand sidebar category &#x27;Cordova Webview&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/css/">CSS</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/database_sql/">Database SQL</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/development_tools/">development tools</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/docker/">Docker</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/docusaurus/">Docusaurus</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/echarts_apache/">Echarts Apache</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/firebase/">Firebase</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/flac/">FLAC</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/flutter/">Flutter</a><button aria-label="Expand sidebar category &#x27;Flutter&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/git/">Git</a><button aria-label="Expand sidebar category &#x27;Git&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/gitbook/">Gitbook</a><button aria-label="Expand sidebar category &#x27;Gitbook&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/go_lang/">Go Lang</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/google_cloud/">Google Cloud</a><button aria-label="Expand sidebar category &#x27;Google Cloud&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/imageai/">ImageAI</a><button aria-label="Expand sidebar category &#x27;ImageAI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/java/">Java</a><button aria-label="Expand sidebar category &#x27;Java&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/javascript/">Javascript</a><button aria-label="Expand sidebar category &#x27;Javascript&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/jquery/">JQuery</a><button aria-label="Expand sidebar category &#x27;JQuery&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/keras/">Keras</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/learning_webpage/">learning webpage</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/linux/">Linux</a><button aria-label="Expand sidebar category &#x27;Linux&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/mac/">Mac</a><button aria-label="Expand sidebar category &#x27;Mac&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/machine_learning/">Machine Learning</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/maximo/">Maximo</a><button aria-label="Expand sidebar category &#x27;Maximo&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/mysql/">MySQL</a><button aria-label="Expand sidebar category &#x27;MySQL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/nodejs/">Node.Js</a><button aria-label="Expand sidebar category &#x27;Node.Js&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/opencv/">OpenCV</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/oracle/">Oracle</a><button aria-label="Expand sidebar category &#x27;Oracle&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/php/">PHP</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/power_bi/">Power BI</a><button aria-label="Expand sidebar category &#x27;Power BI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/python/">Python</a><button aria-label="Expand sidebar category &#x27;Python&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/qt/">QT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/raspberry_pi/">Raspberry Pi</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/react/">React</a><button aria-label="Expand sidebar category &#x27;React&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/react-native/">React-Native</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/redux/">Redux</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/technique/ruby_on_rails/axlsx_rails">ruby_on_rails</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/sql_server/">SQL Server</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/ssh/">SSH</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/swift/">Swift</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/system/">System</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/tensorflow/">TensorFlow</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/vuejs/">Vue.js</a><button aria-label="Expand sidebar category &#x27;Vue.js&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/weather_data_system/">weather data system</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/web_server/">Web Server</a><button aria-label="Expand sidebar category &#x27;Web Server&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/technique/windows/">Windows</a><button aria-label="Expand sidebar category &#x27;Windows&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/technique/words/">Words</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/docs/technique/zzz_waiting_research/">Waiting Research</a><button aria-label="Collapse sidebar category &#x27;Waiting Research&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/technique/zzz_waiting_research/AI-LLM">AI</a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/technique/zzz_waiting_research/"><span itemprop="name">Waiting Research</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">AI</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>AI</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="tokenization">tokenization<a href="#tokenization" class="hash-link" aria-label="Direct link to tokenization" title="Direct link to tokenization">​</a></h2>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">from transformers import AutoTokenizer, AutoModel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Initializing the tokenizer and model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer = AutoTokenizer.from_pretrained(&quot;distilbert-base-uncased&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = AutoModel.from_pretrained(&quot;distilbert-base-uncased&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Step 1: Tokenize raw text using the chosen method (word or subword tokenization)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sentence = &quot;Transformers are quite amazing&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokens = tokenizer.tokenize(sentence)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&quot;Tokens:&quot;, tokens)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Tokens:[&#x27;transformers&#x27;, &#x27;are&#x27;, &#x27;quite&#x27;, &#x27;amazing&#x27;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Step2: Convert tokens into numerical indices corresponding to model vocabulary</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">input_ids = tokenizer.encode(sentence)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&quot;Input Ids:&quot;, input_ids)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Input Ids [[101, 19067, 2024, 3243, 6429, 102]]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Step3: Fetch context-specific embeddings from the model and process through multiple layers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">output = model(input_ids)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">embeddings = output.last_hidden_state</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&quot;Embeddings:&quot;, embeddings);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Embeddings: tensor([[[-0.0555, 0.1111, ..., -0.3933, 0.2311]], ...])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Step4: Process/decode output back into text (Here, we use theembeddings directly to illustrate)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">decoded_output = tokenizer.decode(input_ids[0])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&quot;Decoded output:&quot;, decoded_output)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Decoded output: [CLS] transformers are quite amazing [SEP]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="embeddings-workflow">EMBEDDINGS WORKFLOW<a href="#embeddings-workflow" class="hash-link" aria-label="Direct link to EMBEDDINGS WORKFLOW" title="Direct link to EMBEDDINGS WORKFLOW">​</a></h2>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from transformers import AutoTokenizer, AutoModel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer = AutoTokenizer.from_pretrained(&quot;bert-base-uncased&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = AutoModel.from_pretrained(&quot;bert-base-uncased&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Two sentences with different contexts for the word &quot;rose&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sentence1 = &quot;She took a rose from the garden.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sentence2 = &quot;The sun rose in the morning.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Tokenize sentences to obtain input_ids</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">input_ids1 = tokenizer(sentence1, return_tensors=&quot;pt&quot;)[&quot;input_ids&quot;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">input_ids2 = tokenizer(sentence2, return_tensors=&quot;pt&quot;)[&quot;input_ids&quot;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Obtain embeddings from the model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">with torch.no_grad():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    embeddings1 = model(input_ids1).last_hidden_state</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    embeddings2 = model(input_ids2).last_hidden_state</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Extract the embeddings for the word &quot;rose&quot;.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">embedding1 = embeddings1[0][tokenizer.convert_tokens_to_ids(&quot;rose&quot;)]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">embedding2 = embeddings2[0][tokenizer.convert_tokens_to_ids(&quot;rose&quot;)]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Compare the similarity between the two &quot;rose&quot; embeddings through cosine similarity.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cosine_similarity = torch.nn.CosineSimilarity(dim=0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">similarity = cosine_similarity(embedding1, embedding2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(f&quot;Cosine similarity between the two embeddings:{similarity}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Cosine similarity between the two embeddings: 0.4351</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># sentence1 -&gt; &quot;rose&quot; -&gt; 3123 =&gt; tensor([-0.1230, 0.6666, ..])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># sentence2 -&gt; &quot;rose&quot; -&gt; 3123 =&gt; tensor([-0.0999, 0.7777, ..])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="tokenizerpy">tokenizer.py<a href="#tokenizerpy" class="hash-link" aria-label="Direct link to tokenizer.py" title="Direct link to tokenizer.py">​</a></h2>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Import required libraries</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from transformers import BertModel, AutoTokenizer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import pandas as pd</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Specify the pre-trained model to use: BERT-base-cased</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model_name = &quot;bert-base-cased&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Instantiate the model and tokenizer for the specified pre-trained model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = BertModel.from_pretrained(model_name)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Set a sentence for analysis</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sentence = &quot;When life gives you lemons, don&#x27;t make lemonade.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Tokenize the sentence</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokens = tokenizer.tokenize(sentence)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Create a DataFrame with the tokenizer&#x27;s vocabulary</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vocab = tokenizer.vocab</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vocab_df = pd.DataFrame({&quot;token&quot;: vocab.keys(), &quot;token_id&quot;: vocab.values()})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vocab_df = vocab_df.sort_values(by=&quot;token_id&quot;).set_index(&quot;token_id&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Encode the sentence into token_ids using the tokenizer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">token_ids = tokenizer.encode(sentence)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Print the length of tokens and token_ids</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">len(tokens)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">len(token_ids)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Access the tokens in the vocabulary DataFrame by index</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vocab_df.iloc[101]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vocab_df.iloc[102]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Zip tokens and token_ids (excluding the first and last token_ids for [CLS] and [SEP])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">list(zip(tokens, token_ids[1:-1]))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Decode the token_ids (excluding the first and last token_ids for [CLS] and [SEP]) back into the original sentence</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer.decode(token_ids[1:-1])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Tokenize the sentence using the tokenizer&#x27;s `__call__` method</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer_out = tokenizer(sentence)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Create a new sentence by removing &quot;don&#x27;t &quot; from the original sentence</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sentence2 = sentence.replace(&quot;don&#x27;t &quot;, &quot;&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Tokenize both sentences with padding</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer_out2 = tokenizer([sentence, sentence2], padding=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Decode the tokenized input_ids for both sentences</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer.decode(tokenizer_out2[&quot;input_ids&quot;][0])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer.decode(tokenizer_out2[&quot;input_ids&quot;][1])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="model_embeddingspy">model_embeddings.py<a href="#model_embeddingspy" class="hash-link" aria-label="Direct link to model_embeddings.py" title="Direct link to model_embeddings.py">​</a></h2>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">from transformers import BertModel, AutoTokenizer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from scipy.spatial.distance import cosine</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model_name = &quot;bert-base-cased&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = BertModel.from_pretrained(model_name)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def predict(text):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    encoded_inputs = tokenizer(text, return_tensors=&quot;pt&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return model(**encoded_inputs)[0]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sentence1 = &quot;There was a fly drinking from my soup&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sentence2 = &quot;There is a fly swimming in my juice&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># sentence2 = &quot;To become a commercial pilot, he had to fly for 1500 hours.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokens1 = tokenizer.tokenize(sentence1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokens2 = tokenizer.tokenize(sentence2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">out1 = predict(sentence1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">out2 = predict(sentence2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">emb1 = out1[0:, tokens1.index(&quot;fly&quot;), :].detach()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">emb2 = out2[0:, tokens2.index(&quot;fly&quot;), :].detach()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># emb1 = out1[0:, 3, :].detach()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># emb2 = out2[0:, 3, :].detach()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">emb1.shape</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">emb2.shape</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cosine(emb1, emb2)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-masked_languagepy">3 masked_language.py<a href="#3-masked_languagepy" class="hash-link" aria-label="Direct link to 3 masked_language.py" title="Direct link to 3 masked_language.py">​</a></h2>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Import required libraries</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from transformers import AutoTokenizer, AutoModelForMaskedLM</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from scipy.special import softmax</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import numpy as np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Specify the pre-trained model to use: BERT-base-cased</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model_name = &quot;bert-base-cased&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Instantiate the tokenizer and model for the specified pre-trained model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = AutoModelForMaskedLM.from_pretrained(model_name)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Get the mask token from the tokenizer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mask = tokenizer.mask_token</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Create a sentence with a mask token to be filled in by the model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sentence = f&quot;I want to {mask} pizza for tonight.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Tokenize the sentence</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokens = tokenizer.tokenize(sentence)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Encode the sentence using the tokenizer and return the input tensors</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">encoded_inputs = tokenizer(sentence, return_tensors=&#x27;pt&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Get the model&#x27;s output for the input tensors</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">outputs = model(**encoded_inputs)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Detach the logits from the model&#x27;s output and convert them to numpy arrays</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">logits = outputs.logits.detach().numpy()[0]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Extract the logits for the mask token</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mask_logits = logits[tokens.index(mask) + 1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Calculate the confidence scores for each possible token using softmax</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">confidence_scores = softmax(mask_logits)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Print the top 5 predicted tokens and their confidence scores</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">for i in np.argsort(confidence_scores)[::-1][:5]:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pred_token = tokenizer.decode(i)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    score = confidence_scores[i]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Print the predicted sentence with the mask token replaced by the predicted token, and the confidence score</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(sentence.replace(mask, pred_token), score)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="semantic_indexpy">semantic_index.py<a href="#semantic_indexpy" class="hash-link" aria-label="Direct link to semantic_index.py" title="Direct link to semantic_index.py">​</a></h2>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Import required libraries</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from datasets import load_dataset</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from sentence_transformers import SentenceTransformer, util</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Load the multi_news dataset from Hugging Face and take only the &#x27;test&#x27; split for efficiency</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dataset = load_dataset(&quot;multi_news&quot;, split=&quot;test&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Convert the test dataset to a pandas DataFrame and take only 2000 random samples</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df = dataset.to_pandas().sample(2000, random_state=42)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Load a pre-trained sentence transformer model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = SentenceTransformer(&quot;all-MiniLM-L6-v2&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Encode each summary in the DataFrame using the sentence transformer model and store the embeddings in a list</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">passage_embeddings = list(model.encode(df[&#x27;summary&#x27;].to_list(), show_progress_bar=True))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Print the shape of the first passage embedding</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">passage_embeddings[0].shape</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Declare a query string</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">query = &quot;Find me some articles about technology and artificial intelligence&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Define a function to find relevant news articles based on a given query</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def find_relevant_news(query):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Encode the query using the sentence transformer model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    query_embedding = model.encode(query)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Print the shape of the query embedding</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    query_embedding.shape</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Calculate the cosine similarity between the query embedding and the passage embeddings</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    similarities = util.cos_sim(query_embedding, passage_embeddings)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Find the indices of the top 3 most similar passages</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    top_indicies = torch.topk(similarities.flatten(), 3).indices</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Get the top 3 relevant passages by slicing the summaries at 200 characters and adding an ellipsis</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    top_relevant_passages = [df.iloc[x.item()][&#x27;summary&#x27;][:200] + &quot;...&quot; for x in top_indicies]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Return the top 3 relevant passages</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return top_relevant_passages</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Find relevant news articles for different queries</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">find_relevant_news(&quot;Natural disasters&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">find_relevant_news(&quot;Law enforcement and police&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">find_relevant_news(&quot;Politics, diplomacy and nationalism&quot;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="bert-for-question-answeringipynb">BERT for Question Answering.ipynb<a href="#bert-for-question-answeringipynb" class="hash-link" aria-label="Direct link to BERT for Question Answering.ipynb" title="Direct link to BERT for Question Answering.ipynb">​</a></h2>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Importing necessary libraries</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from transformers import (</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    BertForQuestionAnswering,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    BertTokenizerFast,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from scipy.special import softmax</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import plotly.express as px</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import pandas as pd</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import numpy as np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Defining the context and the question</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">context = &quot;The giraffe is a large African hoofed mammal belonging to the genus Giraffa. It is the tallest living terrestrial animal and the largest ruminant on Earth. Traditionally, giraffes were thought to be one species, Giraffa camelopardalis, with nine subspecies. Most recently, researchers proposed dividing them into up to eight extant species due to new research into their mitochondrial and nuclear DNA, as well as morphological measurements. Seven other extinct species of Giraffa are known from the fossil record.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">question = &quot;How many giraffe species are there?&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Defining the model name and loading the tokenizer and the model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model_name = &quot;deepset/bert-base-cased-squad2&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer = BertTokenizerFast.from_pretrained(model_name)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = BertForQuestionAnswering.from_pretrained(model_name)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Tokenizing the context and the question</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">inputs = tokenizer(question, context, return_tensors=&quot;pt&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer.tokenize(context)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Running the model and getting the start and end scores</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">with torch.no_grad():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    outputs = model(**inputs)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">start_scores, end_scores = softmax(outputs.start_logits)[0], softmax(outputs.end_logits)[0]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Creating a dataframe with the scores and plotting them</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">scores_df = pd.DataFrame({</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Token Position&quot;: list(range(len(start_scores))) * 2,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Score&quot;: list(start_scores) + list(end_scores),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Score Type&quot;: [&quot;Start&quot;] * len(start_scores) + [&quot;End&quot;] * len(end_scores),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">px.bar(scores_df, x=&quot;Token Position&quot;, y=&quot;Score&quot;, color=&quot;Score Type&quot;, barmode=&quot;group&quot;, title=&quot;Start and End Scores for Tokens&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Getting the answer from the model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">start_idx = np.argmax(start_scores)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">end_idx = np.argmax(end_scores)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">answer_ids = inputs.input_ids[0][start_idx: end_idx + 1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">answer_tokens = tokenizer.convert_ids_to_tokens(answer_ids)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">answer = tokenizer.convert_tokens_to_string(answer_tokens)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Part 2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Defining a function to predict the answer to a question given a context</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def predict_answer(context, question):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    inputs = tokenizer(question, context, return_tensors=&quot;pt&quot;, truncation=True, max_length=512)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    with torch.no_grad():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        outputs = model(**inputs)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    start_scores, end_scores = softmax(outputs.start_logits)[0], softmax(outputs.end_logits)[0]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    start_idx = np.argmax(start_scores)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    end_idx = np.argmax(end_scores)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    confidence_score = (start_scores[start_idx] + end_scores[end_idx]) /2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    answer_ids = inputs.input_ids[0][start_idx: end_idx + 1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    answer_tokens = tokenizer.convert_ids_to_tokens(answer_ids)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    answer = tokenizer.convert_tokens_to_string(answer_tokens)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if answer != tokenizer.cls_token:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return answer, confidence_score</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return None, confidence_score</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Defining a new context and predicting answers to some questions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">context = &quot;&quot;&quot;Coffee is a beverage prepared from roasted coffee beans. Darkly colored, bitter, and slightly acidic, coffee has a stimulating effect on humans, primarily due to its caffeine content. It has the highest sales in the world market for hot drinks.[2][unreliable source?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">len(tokenizer.tokenize(context))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">predict_answer(context, &quot;What is coffee?&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">predict_answer(context, &quot;What are the most common coffee beans?&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">predict_answer(context, &quot;How can I make ice coffee?&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">predict_answer(context[4000:], &quot;How many people are dependent on coffee for their income?&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Defining a function to chunk sentences</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def chunk_sentences(sentences, chunk_size, stride):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    chunks = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    num_sentences = len(sentences)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for i in range(0, num_sentences, chunk_size - stride):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        chunk = sentences[i: i + chunk_size]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        chunks.append(chunk)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return chunks</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sentences = [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Sentence 1.&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Sentence 2.&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Sentence 3.&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Sentence 4.&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Sentence 5.&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Sentence 6.&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Sentence 7.&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Sentence 8.&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Sentence 9.&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Sentence 10.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chunked_sentences = chunk_sentences(sentences, chunk_size=3, stride=1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">questions = [&quot;What is coffee?&quot;, &quot;What are the most common coffee beans?&quot;, &quot;How can I make ice coffee?&quot;, &quot;How many people are dependent on coffee for their income?&quot;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">answers = {}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">for chunk in chunked_sentences:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    context = &quot;\n&quot;.join(chunk)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for question in questions:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        answer, score = predict_answer(context, question)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if answer:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            if question not in answers:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                answers[question] = (answer, score)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            else:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                if score &gt; answers[question][1]:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    answers[question] = (answer, score)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">answers</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="gpt-for-instruction-following">GPT for Instruction Following<a href="#gpt-for-instruction-following" class="hash-link" aria-label="Direct link to GPT for Instruction Following" title="Direct link to GPT for Instruction Following">​</a></h2>
<blockquote>
<p><a href="https://huggingface.co/TheFuzzyScientist/diabloGPT_open-instruct" target="_blank" rel="noopener noreferrer">https://huggingface.co/TheFuzzyScientist/diabloGPT_open-instruct</a></p>
</blockquote>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">from transformers import (</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    AutoTokenizer,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    AutoModelForCausalLM,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    DataCollatorForLanguageModeling,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Trainer,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    TrainingArguments,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from datasets import load_dataset</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dataset = load_dataset(&quot;hakurei/open-instruct-v1&quot;, split=&#x27;train&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dataset.to_pandas().sample(20)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def preprocess(example):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    example[&#x27;prompt&#x27;] = f&quot;{example[&#x27;instruction&#x27;]} {example[&#x27;input&#x27;]} {example[&#x27;output&#x27;]}&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return example</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def tokenize_datasets(dataset):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tokenized_dataset = dataset.map(lambda example: tokenizer(example[&#x27;prompt&#x27;], truncation=True, max_length=128), batched=True, remove_columns=[&#x27;prompt&#x27;])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return tokenized_dataset</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dataset = dataset.map(preprocess, remove_columns=[&#x27;instruction&#x27;, &#x27;input&#x27;, &#x27;output&#x27;])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dataset =  dataset.shuffle(42).select(range(100000)).train_test_split(test_size=0.1, seed=42)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">train_dataset = dataset[&#x27;train&#x27;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">test_dataset = dataset[&#x27;test&#x27;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">MODEL_NAME = &quot;microsoft/DialoGPT-medium&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer.pad_token = tokenizer.eos_token</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">train_dataset = tokenize_datasets(train_dataset)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">test_dataset = tokenize_datasets(test_dataset)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">traing_args = TrainingArguments(output_dir=&quot;models/diablo_gpt&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                num_train_epochs=1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                per_device_train_batch_size=32,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                per_device_eval_batch_size=32)\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">trainer = Trainer(model=model,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    args=traing_args,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    train_dataset=train_dataset,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    eval_dataset=test_dataset,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    data_collator=data_collator)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">trainer.train()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Get the trained checkpoint directly</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = AutoModelForCausalLM.from_pretrained(&quot;TheFuzzyScientist/diabloGPT_open-instruct&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def generate_text(prompt):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    inputs = tokenizer.encode(prompt, return_tensors=&#x27;pt&#x27;).to(&quot;cuda&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    outputs = model.generate(inputs, max_length=64, pad_token_id=tokenizer.eos_token_id)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    generated = tokenizer.decode(outputs[0], skip_special_tokens=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return generated[:generated.rfind(&#x27;.&#x27;)+1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">generate_text(&quot;What&#x27;s the best way to cook chiken breast?&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">generate_text(&quot;Should I invest stocks?&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">generate_text(&quot;I need a place to go for this summer vacation, what locations would you recommend&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">generate_text(&quot;What&#x27;s the fastest route from NY City to Boston?&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="t5-for-product-reviews">T5 for Product Reviews<a href="#t5-for-product-reviews" class="hash-link" aria-label="Direct link to T5 for Product Reviews" title="Direct link to T5 for Product Reviews">​</a></h2>
<blockquote>
<p><a href="https://huggingface.co/TheFuzzyScientist/T5-base_Amazon-product-reviews" target="_blank" rel="noopener noreferrer">https://huggingface.co/TheFuzzyScientist/T5-base_Amazon-product-reviews</a></p>
</blockquote>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">!pip install numpy==1.25.1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">!pip install transformers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">!pip install datasets===2.13.1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Importing necessary modules</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import numpy as np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from datasets import load_dataset</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from transformers import DataCollatorWithPadding</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Loading the dataset and removing unnecessary columns</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dataset = load_dataset(&#x27;amazon_us_reviews&#x27;, &#x27;Electronics_v1_00&#x27;, split=&#x27;train&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dataset = dataset.remove_columns([x for x in dataset.features if x not in [&#x27;review_body&#x27;, &#x27;verified_purchase&#x27;, &#x27;review_headline&#x27;, &#x27;product_title&#x27;, &#x27;star_rating&#x27;]])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Filtering the dataset and encoding the &#x27;star_rating&#x27; column</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dataset = dataset.filter(lambda x: x[&#x27;verified_purchase&#x27;] and len(x[&#x27;review_body&#x27;]) &gt; 100).shuffle(42).select(range(100000))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dataset = dataset.class_encode_column(&quot;star_rating&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Splitting the dataset into training and testing sets</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dataset = dataset.train_test_split(test_size=0.1, seed=42, stratify_by_column=&quot;star_rating&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">train_dataset = dataset[&#x27;train&#x27;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">test_dataset = dataset[&#x27;test&#x27;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Initializing the tokenizer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">MODEL_NAME = &#x27;t5-base&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer = T5Tokenizer.from_pretrained(&#x27;t5-base&#x27;)|</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Defining the function to preprocess the data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def preprocess_data(examples):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    examples[&#x27;prompt&#x27;] = [f&quot;review: {example[&#x27;product_title&#x27;]}, {example[&#x27;star_rating&#x27;]} Stars!&quot; for example in examples]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    examples[&#x27;response&#x27;] = [f&quot;{example[&#x27;review_headline&#x27;]} {example[&#x27;review_body&#x27;]}&quot; for example in examples]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    inputs = tokenizer(examples[&#x27;prompt&#x27;], padding=&#x27;max_length&#x27;, truncation=True, max_length=128)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    targets = tokenizer(examples[&#x27;response&#x27;], padding=&#x27;max_length&#x27;, truncation=True, max_length=128)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Set -100 at the padding positions of target tokens</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    target_input_ids = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for ids in targets[&#x27;input_ids&#x27;]:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        target_input_ids.append([id if id != tokenizer.pad_token_id else -100 for id in ids])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    inputs.update({&#x27;labels&#x27;: target_input_ids})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return inputs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Preprocessing the training and testing datasets</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">train_dataset = train_dataset.map(preprocess_data, batched=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">test_dataset = test_dataset.map(preprocess_data, batched=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data_collator = DataCollatorWithPadding(tokenizer=tokenizer)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Fine-tuning the T5 model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">TRAINING_OUTPUT = &quot;./models/t5_fine_tuned_reviews&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">training_args = TrainingArguments(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    output_dir=TRAINING_OUTPUT,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    num_train_epochs=3,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    per_device_train_batch_size=12,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    per_device_eval_batch_size=12,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    save_strategy=&#x27;epoch&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">trainer = Trainer(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model=model,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    args=training_args,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    train_dataset=train_dataset,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data_collator=data_collator,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">trainer.train()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Saving the model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">trainer.save_model(TRAINING_OUTPUT)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Loading the fine-tuned model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = T5ForConditionalGeneration.from_pretrained(TRAINING_OUTPUT)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># or get it directly trained from here:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># model = T5ForConditionalGeneration.from_pretrained(&quot;TheFuzzyScientist/T5-base_Amazon-product-reviews&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Defining the function to generate reviews</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def generate_review(text):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    inputs = tokenizer(&quot;review: &quot; + text, return_tensors=&#x27;pt&#x27;, max_length=512, padding=&#x27;max_length&#x27;, truncation=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    outputs = model.generate(inputs[&#x27;input_ids&#x27;], max_length=128, no_repeat_ngram_size=3, num_beams=6, early_stopping=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return summary</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Generating reviews for random products</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">random_products = test_dataset.shuffle(42).select(range(10))[&#x27;product_title&#x27;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(generate_review(random_products[0] + &quot;, 3 Stars!&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(generate_review(random_products[1] + &quot;, 5 Stars!&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(generate_review(random_products[2] +</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/technique/zzz_waiting_research/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Waiting Research</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#tokenization" class="table-of-contents__link toc-highlight">tokenization</a></li><li><a href="#embeddings-workflow" class="table-of-contents__link toc-highlight">EMBEDDINGS WORKFLOW</a></li><li><a href="#tokenizerpy" class="table-of-contents__link toc-highlight">tokenizer.py</a></li><li><a href="#model_embeddingspy" class="table-of-contents__link toc-highlight">model_embeddings.py</a></li><li><a href="#3-masked_languagepy" class="table-of-contents__link toc-highlight">3 masked_language.py</a></li><li><a href="#semantic_indexpy" class="table-of-contents__link toc-highlight">semantic_index.py</a></li><li><a href="#bert-for-question-answeringipynb" class="table-of-contents__link toc-highlight">BERT for Question Answering.ipynb</a></li><li><a href="#gpt-for-instruction-following" class="table-of-contents__link toc-highlight">GPT for Instruction Following</a></li><li><a href="#t5-for-product-reviews" class="table-of-contents__link toc-highlight">T5 for Product Reviews</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Life</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/">Blog</a></li><li class="footer__item"><a href="https://github.com/xing312101" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.instagram.com/xing312101/?utm_source=qr" target="_blank" rel="noopener noreferrer" class="footer__link-item">Instagram<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/tags">Tags</a></li></ul></div><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/technique">Technique</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/english">English</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/japanese">Japanese</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2020-2025 Xing312101, https://github.com/xing312101</div></div></div></footer></div>
</body>
</html>